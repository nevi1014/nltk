{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461118ab",
   "metadata": {},
   "source": [
    "# NLTK Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472254b",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32ac8c",
   "metadata": {},
   "source": [
    "### Sentence tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a085c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"maxent_ne_chunker\")\n",
    "nltk.download(\"words\")\n",
    "nltk.download(\"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c8494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "example_string = \"\"\"\n",
    "Muad'Dib learned rapidly because his first training was in how to learn.\n",
    "And the first lesson of all was the basic trust that he could learn.\n",
    "It's shocking to find how many people do not believe they can learn,\n",
    "and how many more believe learning to be difficult.\"\"\"\n",
    "sent_tokenize(example_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e9dbed",
   "metadata": {},
   "source": [
    "### Word tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7762a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = word_tokenize(example_string)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953ae73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "german_string = \"\"\"\n",
    "Muad'Dib lernte schnell, denn seine erste Ausbildung galt dem Lernen.\n",
    "Und die erste Lektion überhaupt war das Urvertrauen, das er lernen konnte.\n",
    "Es ist schockierend zu sehen, wie viele Menschen nicht glauben, dass sie lernen können,\n",
    "Und wie viele glauben noch, dass Lernen schwierig sei?\n",
    "\"\"\"\n",
    "word_tokenize(german_string,language='german')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136afd19",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7667e49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = [word for word in stopwords.words()]\n",
    "filtered_list = [word for word in words if word.lower() not in stop_words]\n",
    "filtered_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc62784",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import (\n",
    "    PorterStemmer,\n",
    "    LancasterStemmer\n",
    ")\n",
    "\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "string_for_stemming = \"\"\"\n",
    "The crew of the USS Discovery discovered many discoveries.\n",
    "Discovering is what explorers do.\"\"\"\n",
    "\n",
    "porter_stemmed_words = [porter.stem(word) for word in word_tokenize(string_for_stemming)]\n",
    "lancaster_stemmed_words = [lancaster.stem(word) for word in word_tokenize(string_for_stemming)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdee5b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "porter_stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deef00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster_stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ab239",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d13e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "(pos_tags := nltk.pos_tag(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19840c10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list of POS tags\n",
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b7a90",
   "metadata": {},
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c230bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "[lemmatizer.lemmatize(word) for word in word_tokenize(string_for_stemming)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"worst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73fb7f",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.draw.util import CanvasFrame\n",
    "from nltk.draw import TreeWidget\n",
    "\n",
    "lotr_quote = \"It's a dangerous business, Frodo, going out your door.\"\n",
    "pos_tags = nltk.pos_tag(word_tokenize(lotr_quote))\n",
    "# optional determiner, any number of adjectives, one noun\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "chunk_parser = nltk.RegexpParser(grammar)\n",
    "tree = chunk_parser.parse(pos_tags)\n",
    "\n",
    "# Tkinter necessary\n",
    "#tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='tree.png')) # image drawn by Tkinter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d33ce0",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = \"\"\"\n",
    "Men like Schiaparelli watched the red planet—it is odd, by-the-bye, that\n",
    "for countless centuries Mars has been the star of war—but failed to\n",
    "interpret the fluctuating appearances of the markings they mapped so well.\n",
    "All that time the Martians must have been getting ready.\n",
    "\n",
    "During the opposition of 1894 a great light was seen on the illuminated\n",
    "part of the disk, first at the Lick Observatory, then by Perrotin of Nice,\n",
    "and then by other observers. English readers heard of it first in the\n",
    "issue of Nature dated August 2.\"\"\"\n",
    "\n",
    "\n",
    "def extract_ne(quote):\n",
    "    words = word_tokenize(quote, language='english')\n",
    "    tags = nltk.pos_tag(words)\n",
    "    tree = nltk.ne_chunk(tags, binary=True)\n",
    "    return set(\n",
    "        \" \".join(i[0] for i in t)\n",
    "        for t in tree\n",
    "        if hasattr(t, \"label\") and t.label() == \"NE\"\n",
    "    )\n",
    "\n",
    "\n",
    "extract_ne(quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095097eb",
   "metadata": {},
   "source": [
    "## Concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f55347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.book import *\n",
    "\n",
    "\n",
    "text8.concordance(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf4fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "text8.concordance(\"woman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d65d73",
   "metadata": {},
   "source": [
    "## Dispersion plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "text4.dispersion_plot([\"America\", \"democracy\", \"freedom\", \"duties\", \"citizens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb49d8c",
   "metadata": {},
   "source": [
    "## Frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e544acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "meaningful_words = [word for word in text8 if word.isalpha() and word.lower() not in stop_words]\n",
    "fq = FreqDist(meaningful_words)\n",
    "fq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d52c2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fq.plot(20, cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26027802",
   "metadata": {},
   "source": [
    "## Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text8.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in text8]\n",
    "new_text = nltk.Text(lemmatized_words)\n",
    "new_text.collocations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
